---
title: '深度学习推荐系统[ch02]'
top: false
cover: false
hide: true
toc: true
mathjax: true
date: 2021-12-21 06:45:34
password:
summary:
tags:
    - 深度学习推荐系统
categories:
    - RS
img:
---

# 前深度学习时代——推荐系统的进化之路

传统推荐模型是深度学习推荐模型的基础。

协同过滤、逻辑回归、因子分解机等传统推荐模型仍然凭借其可解释性强、硬件环境要求低、易于快速训练和部署等不可替代的优势，拥有大量适用的应用场景。

## 传统推荐模型的演化关系图

![传统推荐模型的演化关系图](https://cdn.jsdelivr.net/gh/ADCa97/images/img/传统推荐模型的演化关系图.png)

传统推荐模型的发展脉络主要由以下几部分组成：

1. 协同过滤算法族
    
    从物品相似度和用户相似度角度出发，协同过滤衍生出物品协同过滤（ItemCF）和用户协同过滤（UserCF）两种算法。为了使协同过滤能够更好地处理**稀疏共现矩阵问题、增强模型的泛化能力**，从协同过滤衍生出矩阵分解模型（MF），并发展出矩阵分解的各分支模型。

2. 逻辑回归模型族

    与协同过滤仅利用用户和物品之间的显式或隐式反馈信息相比，逻辑回归能够**利用和融合更多用户、物品及上下文特征**。从LR模型衍生出的模型包括增强了非线性能力的大规模分片线性模型（LS-PLM），由逻辑回归发展出来的FM模型，以及与多种不同模型配合使用后的组合模型，等等。

3. 因子分解机模型族

    因子分解机在传统逻辑回归的基础上，加入了二阶部分，使模型具备了**进行特征组合**的能力。更进一步，在因子分解机基础上发展出来的域感知因子分解机（FFM）则通过加入特征域的概念，进一步加强了因子分解机特征交叉的能力。

4. 组合模型

    为了**融合多个模型**的优点，将不同模型组合使用是构建推荐模型常用的方法。GBDT+LR（梯度提升决策树+逻辑回归）组合模型是在业界影响力较大的组合方式。此外，组合模型中体现出的**特征工程模型化**的思想，也成了深度学习推荐模型的引子和核心思想之一。

## 协同过滤——经典的推荐算法

### [UserCF](https://github.com/ADCa97/DLRS/blob/main/ch02/UserCF.py)

基于用户的协同过滤算法主要包括两个步骤：

+ 找到和目标用户兴趣相似的用户集合
    
    用户相似度计算包括Jaccard相似度、余弦相似度、皮尔逊相关系数等：

    1. 余弦相似度

        ![余弦相似度](https://cdn.jsdelivr.net/gh/ADCa97/images/img/余弦相似度.png)
    
    2. 皮尔逊相关系数

        相比余弦相似度，皮尔逊相关系数通过使用用户平均分对各独立评分进行修正，减少了用户评分偏置的影响。

        ![皮尔逊相关系数](https://cdn.jsdelivr.net/gh/ADCa97/images/img/皮尔逊相关系数.png)

    3. 基于皮尔逊系数的思路，还可以通过引入物品平均分的方式，减少物品评分偏置对结果的影响

        ![引入物品平均分的皮尔逊系数](https://cdn.jsdelivr.net/gh/ADCa97/images/img/引入物品平均分的皮尔逊系数.png)

+ 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户

    利用用户相似度和相似用户的评价的加权平均获得目标用户的评价预测。

    ![目标用户的评价预测](https://cdn.jsdelivr.net/gh/ADCa97/images/img/目标用户的评价预测.jpg)

**存在的问题**

+ 用户数远远大于物品数的情形下，用户相似度矩阵的存储开销非常大，用户数的增长会导致用户相似度矩阵的空间复杂度以$n^2$的速度快速增长

+ 用户的历史数据向量非常稀疏，对于只有几次购买或者点击行为的用户来说，找到相似用户的准确度是非常低的，这导致UserCF不适用于那些正反馈获取较困难的应用场景（如酒店预订、大件商品购买等低频应用）

### [ItemCF](https://github.com/ADCa97/DLRS/blob/main/ch02/ItemCF.py)

基于物品的协同过滤算法主要分为两步：

+ 计算物品之间的相似度

    ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。

    通过计算共现矩阵中物品列向量的相似度得到物品之间的相似矩阵，再找到用户的历史正反馈物品的相似物品进行进一步排序和推荐。

+ 根据物品的相似度和用户的历史行为给用户生成推荐列表

    对相似物品集合中的物品，利用相似度分值进行排序，生成最终的推荐列表。
    ![物品最终的相似度](https://cdn.jsdelivr.net/gh/ADCa97/images/img/物品最终的相似度.png)

**ItemCF的一个优势就是可以提供推荐解释，即利用用户历史上喜欢的物品为现在的推荐结果进行解释。**

### UserCF和ItemCF的综合比较

UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度；而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承。

协同过滤是一个非常直观、可解释性很强的模型，但它并不具备较强的泛化能力，换句话说，协同过滤无法将两个物品相似这一信息推广到其他物品的相似性计算上。

**泛化能力弱**

如果两个用户没有相同的历史行为，两个物品没有相同的人购买，那么这两个用户和两个物品的相似度都将为0（因为协同过滤智能利用用户和物品自己的信息及逆行相似度计算，这就使协同过滤不具备泛化利用全局信息的能力）。

**协同过滤的天然缺陷——推荐结果的头部效应较明显，处理稀疏向量的能力弱**

另外，协同过滤仅利用用户和物品的交互信息，无法有效地引入用户年龄、性别、商品描述、商品分类、当前时间等一系列用户特征、物品特征和上下文特征，这无疑造成了有效信息的遗漏。***为了在推荐模型中引入这些特征，推荐系统逐渐发展到以逻辑回归模型为核心的、能够综合不同类型特征的机器学习模型的道路上。***

## 矩阵分解算法——协同过滤的进化

针对协同过滤算法的**头部效应较明显、泛化能力较弱**的问题，矩阵分解算法被提出。矩阵分解在协同过滤算法中“共现矩阵”的基础上，加入了**隐向量**的概念，加强了模型处理稀疏矩阵的能力，针对性地解决了协同过滤存在的主要问题。

在“矩阵分解”的算法框架下，用户和物品的隐向量是通过分解协同过滤生成的共现矩阵得到的。

![矩阵分解过程](https://cdn.jsdelivr.net/gh/ADCa97/images/img/矩阵分解过程.png)

矩阵分解算法将$m*n$维的共现矩阵$R$分解为$m*k$维的用户矩阵$U$和$k*n$维物品矩阵$V$相乘的形式。其中$m$是用户数量，$n$是物品数量，$k$是隐向量的维度。

$k$的大小决定了隐向量表达能力的强弱。$k$的取值越小，隐向量包含的信息越少，模型的泛化程度越高；反之，$k$的取值越大，隐向量的表达能力越强，但泛化程度相应降低。此外$k$的取值还与矩阵分解的求解复杂度直接相关。在具体应用中，$k$的取值要经过多次试验找到一个推荐效果和工程开销的平衡点。

### 矩阵分解的求解过程

对矩阵进行分解的主要方法有三种：**特征值分解**、**奇异值分解**和**梯度下降**。

+ 奇异值分解

    + 要求原始的共现矩阵是稠密的

    + 传统奇异值分解的计算复杂度达到了$O(mn^2)$的级别，不适用于解决大规模稀疏矩阵的矩阵分解问题

+ 梯度下降

    矩阵分解的目标函数是让原始评分$r_{ui}$与用户向量和物品向量之积$q_i^Tp_u$的差尽量小，这样才能最大限度地保存共现矩阵的原始信息。

    ![矩阵分解的目标函数](https://cdn.jsdelivr.net/gh/ADCa97/images/img/矩阵分解的目标函数.png)

    **消除用户和物品打分的偏差**

    不同用户的打分体系不同，不同物品的衡量标准也有所区别，为了消除用户和物品打分的偏差，常用的做法是在矩阵分解时加入用户和物品的偏差向量。

    ![加入用户和物品的偏差向量](https://cdn.jsdelivr.net/gh/ADCa97/images/img/加入用户和物品的偏差向量.png)

    加入用户和物品的打分偏差项之后，矩阵分解得到的隐向量更能反应不同用户对不同物品的“真实”态度差异，也就更容易捕捉评价数据中有价值的信息，从而避免结果有偏。

### 矩阵分解的优点和局限性

1. 泛化能力强。在矩阵分解算法中，由于隐向量的存在，使任意的用户和物品之间都可以得到预测分值。而隐向量的生成过程其实是对共现矩阵进行全局拟合的过程，因此**隐向量其实是利用全局信息生成的，有更强的泛化能力**

2. 空间复杂度低。不需要再存储协同过滤模型服务阶段所需的“庞大”的用户相似性或物品相似性矩阵，只需要存储用户和物品隐向量

3. 更好的扩展性和灵活性。矩阵分解的最终产出是用户和物品隐向量，这其实与深度学习中的Embedding思想不谋而合，因此矩阵分解的结果也非常便于与其他特征进行组合和拼接，并便于与深度学习网络进行无缝结合

与协同过滤一样，矩阵分解同样不方便加入用户、物品和上下文相关的特征，这使得矩阵分解丧失了利用很多有效信息的机会，同时在缺乏用户历史行为时，无法进行有效的推荐。

## 逻辑回归——融合多种特征的推荐模型

## 从FM到FFM——自动特征交叉的解决方案

## GBDT+LR——特征工程模型化的开端

## LS-PLM——阿里巴巴曾经的主流推荐模型